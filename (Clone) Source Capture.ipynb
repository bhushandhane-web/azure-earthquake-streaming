{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60fa5e75-5c39-4b6c-a9b9-2123bfeeef56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install azure-eventhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee23e477-4176-4b61-86b1-3e2bc0cf81f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install azure-eventhub requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef4add97-421c-4422-af24-fd9c0f1a1370",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd48c60c-0c93-428d-85ff-0c8f7a2e6915",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import requests\n",
    "from azure.eventhub import EventHubProducerClient, EventData\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION\n",
    "# ==========================================\n",
    "\n",
    "# üî¥ PASTE YOUR CONNECTION STRING HERE\n",
    "# It looks like: \"Endpoint=sb://<namespace>.servicebus.windows.net/;SharedAccessKeyName=...;SharedAccessKey=...\"\n",
    "connection_string = \"Endpoint=sb://YOUR_EVENT_HUB_NAMESPACE...\"\n",
    "\n",
    "# Ensure this matches your Event Hub Instance name exactly\n",
    "event_hub_name = \"earthquake-stream\"\n",
    "\n",
    "# Data Source (USGS Live Feed)\n",
    "api_url = \"https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_hour.geojson\"\n",
    "\n",
    "# ==========================================\n",
    "# 2. MAIN PRODUCER LOGIC\n",
    "# ==========================================\n",
    "\n",
    "def run_earthquake_producer():\n",
    "    print(f\"üöÄ Starting Producer for Event Hub: {event_hub_name}\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "\n",
    "    # Initialize the Client\n",
    "    try:\n",
    "        producer = EventHubProducerClient.from_connection_string(\n",
    "            conn_str=connection_string,\n",
    "            eventhub_name=event_hub_name\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Connection Error: Check your connection string! Details: {e}\")\n",
    "        return\n",
    "\n",
    "    with producer:\n",
    "        while True:\n",
    "            try:\n",
    "                # --- Step A: Fetch Live Data ---\n",
    "                response = requests.get(api_url)\n",
    "                \n",
    "                if response.status_code != 200:\n",
    "                    print(f\"‚ö†Ô∏è API Error (Status {response.status_code}). Retrying in 10s...\")\n",
    "                    time.sleep(10)\n",
    "                    continue\n",
    "\n",
    "                data = response.json()\n",
    "                features = data.get('features', [])\n",
    "                \n",
    "                if not features:\n",
    "                    print(\"üí§ No recent earthquakes found. Waiting...\")\n",
    "                    time.sleep(60)\n",
    "                    continue\n",
    "\n",
    "                # --- Step B: Batch & Send Events ---\n",
    "                event_data_batch = producer.create_batch()\n",
    "                count = 0\n",
    "                \n",
    "                for feature in features:\n",
    "                    # Convert single quake dictionary to JSON string\n",
    "                    message_body = json.dumps(feature)\n",
    "                    \n",
    "                    try:\n",
    "                        # Try adding to the current batch\n",
    "                        event_data_batch.add(EventData(message_body))\n",
    "                        count += 1\n",
    "                    except ValueError:\n",
    "                        # If batch is full (max size limit), send it immediately\n",
    "                        producer.send_batch(event_data_batch)\n",
    "                        print(f\"   -> Batch limit reached. Sending intermediate batch...\")\n",
    "                        \n",
    "                        # Start a new batch\n",
    "                        event_data_batch = producer.create_batch()\n",
    "                        event_data_batch.add(EventData(message_body))\n",
    "                        count += 1\n",
    "\n",
    "                # Send the remaining events in the final batch\n",
    "                if count > 0:\n",
    "                    producer.send_batch(event_data_batch)\n",
    "                    \n",
    "                    # Log success with timestamp\n",
    "                    current_time = time.strftime(\"%H:%M:%S\")\n",
    "                    print(f\"‚úÖ [{current_time}] Successfully pushed {count} events to Azure Event Hubs.\")\n",
    "\n",
    "                # --- Step C: Rate Limiting ---\n",
    "                # USGS updates every 60 seconds. We wait to avoid spamming duplicate data.\n",
    "                time.sleep(60)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå CRITICAL ERROR: {e}\")\n",
    "                print(\"Re-attempting in 10 seconds...\")\n",
    "                time.sleep(10)\n",
    "\n",
    "# ==========================================\n",
    "# 3. EXECUTION\n",
    "# ==========================================\n",
    "if __name__ == \"__main__\":\n",
    "    run_earthquake_producer()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "(Clone) Source Capture",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
